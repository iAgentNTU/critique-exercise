\documentclass[a4paper]{article}
% Preamble Area

\usepackage{geometry} 
\usepackage{graphicx}


\newtheorem{assumption}{Assumption}

 
\title{Paper Commentary Exercise}
\author{Janet Huang}

\begin{document}
\maketitle
% -----------------------
% Paper Name -- Rating: __/5
% 1 summary
% 3 positive topics
% 1 criticism 
% -----------------------

% -----------------------
% date: 2014/12/25
\section{Human Computation Tasks with Global Constraints -- Rating: 4/5}
% summary
The paper \cite{Zhang2012b} attemps to solve complex task with global constraints such as itinerary planning. They introduce a collaborative planning system called Mobi that demostrates a novel crowdware paradigm, where the participants can view and make contributions based on current needs.

% positive
Instead of solving complex problems automatically by programs, the paper aims to use mixed-initiative solution to leverage the power of crowds and computers. They argue for an alternative crowdaware paradigm which allows people to collaborate with others and make contributions as they wish under system-generated advices.

% criticism
A successful social system relies on participants constantly contribute their efforts. The first experiment evaluates the effectiveness of the feature of todo items and the second experiment evaluates the system for recruited people but not for real users. I'm curious about whether the users engage on such kinds of collaboration  s and make sustainable contributions.


% -----------------------
% date: 2014/12/17
\section{Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk -- Rating: 4/5}
% summary
The paper \cite{Irani2013} introduces Turkopticon, an activist system that allows workers to publicize and evaluate their relationship with employers. They discuss their lessons learned from intervening in existing, large-scale socio-technical systems.

% positive #1
Rather than focusing on employers' view, the paper focuses on worker-employer relationsihps. They aims to make the relations visible and provoke ehtical and political debate.

% positive #2
The authors defines four qualities for evaluating the performance of employers. The four qualities are ``Communicativity'', ``Generosity'', ``Fairness'' and ``Promptness''. The workers are allowed to provide feedbacks in a free-form box and they can share more detailed stories of their experience.

% positive #3
The authors had collected reliable data during four-years deployment. The workers agreed that the Turkopticon help them a lot and provide them an oppertunity to reveal their opinions.

% criticism 
To get higher reputations, the employers may create some fake workers to raise up their scores. The issue requires to be solved such that the activist technologies can be sustained on intervening in the large socio-technical systems.


% -----------------------
% date: 2014/12/05
\section{Structured Labeling to Facilitate Concept Evolution in Machine Learning -- Rating: 4.5/5}
% summary
The paper \cite{Kulesza2014} introduces the notion of concept evolution which can result in incosistent labels and thus be damaging to machine learning. To address the problem, they propose two structure labeling solutions for helping people define and refine their concept in a consistent manner as they label. They conducted a series of experiments illustrating the impact of concept evolution in practice. The results show that tructured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.

% positive #1: address a distrinct probelm (concept evolution)
The authors address the concept evolution problem in labeling data of machine learning. They found that people labeling the same group of data twice with a four-week gap have only 81\% consistent with thier initial labels.

% positive #2: 
They introduce structured labeling as a novel approach to dealing with the concept evolution problem. Their experiment showed that people prefered structured labeling over traditional labeling and that structured labeling imporves label consistency but at a cost of speed.

% positive $3
The following up experiment comparing label consistency over time showed that structured labeling helped people recall their earlier labeling decisions and increased their consistency over time.

% critique
The paper used TFIDF to automatically generate and display text summaries for each group of labels. The user-generated labels are hard to be aggregated by a similar concept if only using term-frequency based similairy method. Embeding a knowledge graph may improve the structured labeling.

% -----------------------
% date: 2014/11/14
\section{Fine-Grained Visual Comparisons with Local Learning -- Rating: 4/5}
% summary
% RQ: how to idnetify neighboring training pairs: we show how to learn pairs analogous to the input, accounting for the attribute-specefic visual similarities.
To solve fine-grained viusal comparisons, the paper \cite{fine-grained} proposes a local learning approach to train comparative attributes based on fine-grained analogous pairs and introduces a new dataset specialized to the problem. The results indicate that more labeled data is not nessarily preferable to isolating the right data. \\

% positive #1: visual comparisons need not be transitive, so use local function rather global function
The authors propose an interesting idea about visual comparison. They think that the visual comparisons need not be transitive, so they choose local ranking function instead of global function. \\

% positive #2: compare two state-of-the-art method on three dataset
They did a large scale experiments on evaluating their methods. They've compared two state-of-the-art methods on three databases. I think the results have high reliability. \\

% positive #3: clear definition and queation
The approach is described by clear definition and equations. The reader can understand the detail much easier. \\

% criticism: how to choose the subtle detail parameter?
Choosing the suitable relative attribute between two images is a key for this method. If there is a dependency between two attribute, are the visual comparison results still not transitive?

% ----------------------
% date: 2014/10/31
\section{Scalable Multi-label Annotation -- Rating: 4/5}
Deng \emph{et~al.} \cite{Deng2014} address the scalablity issue of multi-label annotation. They proposes an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution to yield significant savings for image labeling tasks.\\

% positive #1: 3 key observations
The paper clearly identifies three key obersvations for labels in real world scenarios. The labels are correlated, sparse and naturally form a hierarchy.\\

% positive #2:
The authors propose a theoretical analysis and a practical algorithm to satify the assumptions. They clearly define the utlity and cost function and use a pseudo code to describe the algorithm.\\

% positive #3:
The paper applys the algorithm on a real image dataset in real world scenarios. The results show that their algorithm accuires up to 6Ã— savings compared to the na\"{i}ve approach.\\

% criticism:
I wish they can provide a complete example to describe the process of anaylysis and demostrate the power of algorithm for reducing the costs. To achieve the goal of scalablity, we should select the high-utility queries with low cost. I wish the authors can provide their ideas on the trade-off between utility and cost.


% ----------------------- import bibtex ----------------------------
\bibliographystyle{abbrv}
\bibliography{janetyc_critique}


\end{document}
